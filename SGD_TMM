# Important note: Tensorflow used here is TF. 2.12.0, CPU mode is used

import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
print('tf.__version__:')
print(tf.__version__)
import math
import scipy.interpolate
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.python.keras import Model
# from tensorflow.keras import Model
import tensorflow_probability as tfp
from scipy.stats import norm
from scipy.stats import cauchy
from scipy.interpolate import interp1d





# import pylab as pl

# Set CPU as available physical device
my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')
tf.config.experimental.set_visible_devices(devices=my_devices, device_type='CPU')

# To find out which devices your operations and tensors are assigned to
tf.debugging.set_log_device_placement(True)


# Important Note: Because the algorithm is based on back-propagation, sometimes it might be stuck at LOCAL MINIMUM. Running the code for several times might boost the performance.
# Important NOTE: unless specified, all the units are: thickness in nm, frequency of light in nm, refractive index of material in n and k (complex n)
# The ploting might be converted into wavenumber, but all the calculation are in nm (wavelength)
# Important Node: the parameters of strucuture is printed instead of exported into a file

# Important Note: TE mode is calculated.
# Important Note: hyper-parameters: learning rate, step, learning epoches, the components of loss function, batch size


# Calculate the characteristic matrix of a single layer
def Ch_Matrix(theta_in, n0, n1, d1, n2, k0):
    one_m = tf.constant(1.0, tf.float64)
    zeros_m = tf.constant(0.0, tf.float64)
    imag = tf.complex(zeros_m, one_m)

    W, L = n0.shape

    zeros_temp = tf.constant(0.0, dtype=tf.float64, shape=(W, 1))
    zeros_complex = tf.complex(zeros_temp, zeros_m)

    ones_temp = tf.constant(1.0, dtype=tf.float64, shape=(W, 1))
    ones_complex = tf.complex(ones_temp, zeros_m)

    k0 = tf.complex(k0, zeros_m)
    di = tf.complex(d1, zeros_m)
    di = tf.reshape(di, (W, 1))
    n1 = tf.reshape(n1, (W, 1))
    n2 = tf.reshape(n2, (W, 1))
    cos1 = 1 / n1 * tf.math.sqrt(n1 ** 2 - (n0 * tf.math.sin(theta_in)) ** 2)
    cos2 = 1 / n2 * tf.math.sqrt(n2 ** 2 - (n0 * tf.math.sin(theta_in)) ** 2)
    # print (cos1, 'cos1')
    rs12 = (n1 * cos1 - n2 * cos2) / (n1 * cos1 + n2 * cos2)

    ts12 = 2 * n1 * cos1 / (n1 * cos1 + n2 * cos2)
    ts12 = tf.expand_dims(ts12, axis=2)

    optical_pass = di * k0 * n1 * cos1
    # print (optical_pass.shape, di.shape, k0.shape, n1.shape, cos1.shape, W, 'all shapes')
    Matrix = [[tf.math.exp(-imag * optical_pass), zeros_complex], [zeros_complex, tf.math.exp(imag * optical_pass)]]
    Matrix = tf.reshape(Matrix, shape=(4, W))
    Matrix = tf.reshape(Matrix, shape=(2, 2, W))
    Matrix = tf.transpose(Matrix, [2, 1, 0])

    M_t2 = [[ones_complex, rs12], [rs12, ones_complex]]
    M_t2 = tf.reshape(M_t2, shape=(4, W))
    M_t2 = tf.reshape(M_t2, shape=(2, 2, W))
    M_t2 = tf.transpose(M_t2, [2, 1, 0])

    M2 = tf.linalg.matmul(Matrix, M_t2) / ts12

    return M2


# Transfer matrix calculation of all the layers
def TMM(theta_in, n0, n, d, k0):
    temp = n
    W, L = temp.shape
    L = L - 1

    one_m = tf.constant(1.0, tf.float64, shape=[W, 1])
    zeros_m = tf.constant(0.0, tf.float64, shape=[W, 1])
    one_m_complex = tf.complex(one_m, zeros_m)

    cos0 = tf.math.cos(theta_in)
    cos1 = 1 / n[0, 0] * tf.math.sqrt(n[0, 0] ** 2 - (n0 * tf.math.sin(theta_in)) ** 2)
    ts01 = 2 * n0 * cos0 / (n0 * cos0 + n[0, 0] * cos1)
    ts01 = tf.expand_dims(ts01, axis=2)
    rs01 = (n0 * cos0 - n[0, 0] * cos1) / (n0 * cos0 + n[0, 0] * cos1)
    # Take care of the matrix shape conversion
    M01 = [[one_m_complex, rs01], [rs01, one_m_complex]]
    M01 = tf.reshape(M01, shape=(4, W))
    M01 = tf.reshape(M01, shape=(2, 2, W))
    M01 = tf.transpose(M01, [2, 1, 0])

    M0 = M01 / ts01
    Transfer = M0

    # Loop the layers
    for layer_ind in range(L):
        Temp_transfer_matrix = Ch_Matrix(theta_in, n0, n[:, layer_ind], d[:, layer_ind], n[:, layer_ind + 1], k0)
        # print ('transfer matrix',Temp_transfer_matrix)
        # print ('medium transfer', layer_ind, Temp_transfer_matrix)
        Transfer = tf.linalg.matmul(Transfer, Temp_transfer_matrix)

    return Transfer


# Calculate the reflectance from the TMM
def reflectance(wavelength, theta_in, n0, n, d):
    one_m = tf.constant(1.0, tf.float64)
    zeros_m = tf.constant(0.0, tf.float64)
    print(one_m)
    theta_in = tf.complex(theta_in, zeros_m)

    k0 = 1 / wavelength * 2 * 3.1415926
    k0 = tf.expand_dims(k0, axis=1)

    Matrix_overall = TMM(theta_in, n0, n, d, k0)

    m00 = Matrix_overall[:, 0, 0]
    m10 = Matrix_overall[:, 1, 0]
    refte = m10 / m00

    Reflectance = (tf.math.abs(refte)) ** 2
    # Important note: the reflectance calculated here is <=1

    return Reflectance


# Define Drude Model
# carrier density is carrier density of CdO
# Model of CdO is taken from Nolen, J. Ryan, et al. "Ultraviolet to far-infrared dielectric function of n-doped cadmium oxide thin films." Physical Review Materials 4.2 (2020): 025202.
# Frequency is in cm-1
def Drude(carrier, wavelength):
    k = 10000000 / wavelength  # k is in wavenumber
    w = (2.998e+10) * k  # Frequency - Hz
    #     l=len(frequency)
    # Constants
    q = 1.60217662e-19
    m = 9.10938e-31
    eps_o = 8.854e-12
    C_CdO = 1.47
    mo_CdO = 0.1
    #     CdO Properties
    n1 = carrier * (1e+20);  # CC in cm^-3
    print(n1, 'carrier_concnetration')
    mu1 = 200.0  # mobility in cm^2/(V-s)
    eps_CdO_inf = 5.1  # High frequency permittivity

    n1_eff = n1 * (1e-20)
    m_eff_1 = mo_CdO * (1 + (2 * C_CdO) * ((0.19732697 ** 2) / (mo_CdO * 510998.5)) * (3 * 3.14 * n1_eff * 10 ** 8) ** (
            2 / 3)) ** (1 / 2)
    wp1 = (1000 / (2 * 3.14)) * ((n1 * q ** 2) / (m_eff_1 * m * eps_o)) ** 0.5;  # plasma frequency of layer 1
    gamma1 = (10000 / (2 * 3.14)) * (q / (mu1 * m_eff_1 * m))  # damping of layer 1 in Hz
    print(gamma1, w, wp1, 'gamma1, w, wp1')
    eps_1_real = eps_CdO_inf - (wp1 ** 2 / (w ** 2 + gamma1 ** 2))
    eps_1_imag = (gamma1 * wp1 ** 2) / (w * (w ** 2 + gamma1 ** 2))
    DF_1 = tf.complex(eps_1_real, eps_1_imag)
    refractive_index = tf.math.sqrt(DF_1)
    refractive_index = tf.reshape(refractive_index, [len(w), 1])
    return refractive_index


def Ge_nk(wavelength):
    x = 0.001*wavelength  # k is in wavenumber
    frequency_length=tf.size(x)
    eps_1_real = 0.5159*x**(-2.333)+4.021
    eps_1_imag = 0.1755*x**(-3.169)-0.00328
    refractive_index_Ge = tf.complex(eps_1_real, eps_1_imag)
    refractive_index_Ge = tf.reshape(refractive_index_Ge, [frequency_length, 1])
    return refractive_index_Ge

def ZnS_nk(wavelength):
    x = 0.001*wavelength  # k is in wavenumber
    frequency_length = tf.size(x)
    eps_1_real = tf.math.sqrt(1.010356 + 3.619092 * x**2 / (x**2 - 0.02345364) + 0.508130 * x**2 / (x**2 - 0.099946) + 2.219955 * x**2 / (x**2 - 1148.729))
    eps_1_imag = 0.0000000001*x
    refractive_index_ZnS = tf.complex(eps_1_real, eps_1_imag)
    refractive_index_ZnS = tf.reshape(refractive_index_ZnS, [frequency_length, 1])
    return refractive_index_ZnS

def Ag_nk(wavelength):
    x = 0.001*wavelength  # k is in wavenumber
    frequency_length = tf.size(x)
    eps_1_real = 0.1663*x**1.848-0.01711
    eps_1_imag = 7.962*x**0.9085-1.565
    refractive_index_Ag = tf.complex(eps_1_real, eps_1_imag)
    refractive_index_Ag = tf.reshape(refractive_index_Ag, [frequency_length, 1])
    return refractive_index_Ag

def set_target():
    # The following set target function is to set a gaussian shaped target
    # Note: the shape of Tamm plasmon is normally Lorentz shaped, so please use "Cauchy.pdf" from scipy.stats for best performance

    # Define the frequency range and the target spectra
    wavenumber_unshuffled = np.arange(710, 12500, 1)
    wavelength_unshuffled = 10000000 / wavenumber_unshuffled
    frequency_length = len(wavelength_unshuffled)
    wavelength_unshuffled = wavelength_unshuffled.reshape(frequency_length, )
    wavelength_unshuffled = np.float64(wavelength_unshuffled)
    wavelength_plot = wavelength_unshuffled.astype(np.float64)

    # Set target reflectance function
    Ref_target_uns = np.ones((frequency_length, 1)) * 100

    # The following is to set several dips.
    absorption2 = norm.pdf(wavelength_unshuffled, 5300, 260)
    # absorption2 = cauchy.pdf(wavelength_unshuffled, 1060,10)
    absorption2 = 0.7 * absorption2 / (absorption2.max()) * 100
    absorption2 = np.reshape(absorption2, (frequency_length, 1))

    #absorption3 = norm.pdf(wavelength_unshuffled, 10600, 120)
    absorption3 = cauchy.pdf(wavelength_unshuffled, 10600, 100)
    absorption3 = 1 * absorption3 / (absorption3.max()) * 100
    absorption3 = np.reshape(absorption3, (frequency_length, 1))

    absorption4 = norm.pdf(wavelength_unshuffled, 5700, 300)
    # absorption4 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption4 = 0.65*absorption4 / (absorption4.max()) * 100
    absorption4 = np.reshape(absorption4, (frequency_length, 1))

    absorption5 = norm.pdf(wavelength_unshuffled, 6500, 600)
    # absorption5 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption5 = 0.75*absorption5 / (absorption5.max()) * 100
    absorption5 = np.reshape(absorption5, (frequency_length, 1))

    absorption6 = norm.pdf(wavelength_unshuffled, 7300, 300)
    # absorption6 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption6 = 0.65 *absorption6 / (absorption6.max()) * 100
    absorption6 = np.reshape(absorption6, (frequency_length, 1))


    absorption7 = norm.pdf(wavelength_unshuffled, 7700,260)
    # absorption7 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption7 = 0.7*absorption7 / (absorption7.max()) * 100
    absorption7 = np.reshape(absorption7, (frequency_length, 1))

    absorption8 = norm.pdf(wavelength_unshuffled, 2200, 400)
    # absorption7 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption8 = 0.9 * absorption8 / (absorption8.max()) * 100
    absorption8 = np.reshape(absorption8, (frequency_length, 1))

    absorption9 = norm.pdf(wavelength_unshuffled, 1200, 450)
    # absorption9 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption9 = 0.9 * absorption9 / (absorption9.max()) * 100
    absorption9 = np.reshape(absorption9, (frequency_length, 1))

    absorption10 = norm.pdf(wavelength_unshuffled, 650, 200)
    # absorption9 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption10 = 0.4 * absorption10 / (absorption10.max()) * 100
    absorption10 = np.reshape(absorption10, (frequency_length, 1))

    absorption11 = norm.pdf(wavelength_unshuffled, 6500, 200)
    # absorption9 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption11 = 0.20 * absorption11 / (absorption11.max()) * 100
    absorption11 = np.reshape(absorption11, (frequency_length, 1))

    absorption12 = norm.pdf(wavelength_unshuffled, 6500, 200)
    # absorption9 = cauchy.pdf(wavelength_unshuffled, 10600, 50)
    absorption12 = 0.20 * absorption12 / (absorption12.max()) * 100
    absorption12 = np.reshape(absorption12, (frequency_length, 1))

    Ref_target_uns = Ref_target_uns - 0*absorption2 - absorption4 - absorption5 - absorption6 - 0*absorption7 - 0*absorption3 - 1*absorption8 - 1*absorption9 - absorption10 -absorption11
    # Ref_target_uns = Ref_target_uns -1*absorption3
    Ref_target_uns = Ref_target_uns.astype(np.float64)

    wavelength_plot = np.reshape(wavelength_plot, [frequency_length, 1])
    important_id = np.where(Ref_target_uns < 96)
    wave_important = wavelength_plot[important_id]
    Ref_important = Ref_target_uns[important_id]

    # print(len(wave_important), 'data point in resonance')
    # plt.figure()
    # # plt.plot(10000000/wavelength_plot, Ref_target_uns)
    # # plt.xlabel('frequency cm-1')
    # plt.plot(wavelength_unshuffled, Ref_target_uns)
    # plt.xlabel('Wavelength nm')
    # plt.ylabel('Reflectivity (%)')
    # plt.title('target spectra')
    # plt.show()

    return wavelength_plot, Ref_target_uns, wave_important, Ref_important


import numpy as np

def load_and_interpolate_excel(file_path, target_wavelengths):
    target_wavelengths = 10000000 /target_wavelengths
    data = pd.read_excel(file_path)
    wave = data.iloc[:, 0].values
    n = data.iloc[:, 1].values
    k = data.iloc[:, 2].values
    frequency_length = len(target_wavelengths)
    print('target_wavelengths-----------------------------')
    print(target_wavelengths)
    # Convert target_wavelengths to NumPy array
    # 创建 TensorFlow 会话
    # target_wavelengths_np = target_wavelengths.numpy()
    # Interpolate the data to match target_wavelengths
    n_interp_func = interp1d(wave, n, kind='linear', fill_value='extrapolate')
    k_interp_func = interp1d(wave, k, kind='linear', fill_value='extrapolate')
    n_interp = n_interp_func(target_wavelengths)
    k_interp = k_interp_func(target_wavelengths)

    # Convert interpolated data to complex form
    AlO_complex = tf.complex(n_interp, k_interp)
    XY_complex = tf.reshape(AlO_complex, [frequency_length, 1])

    return XY_complex

# Important note: the optical structure is defined here. The layer_length is the total layer number without the substrate
# Important note: layer thickness of each layer is limited to 50-850 nm, by a sigmoid function, and the purpose is to make the design realistic for growing.
class MyModel(Model):
    # class MyModel (Model):
    def __init__(self):
        super(MyModel, self).__init__()
        # Important note: Randomly initialize the parameters
        # Note, all the values are in float64 and complex128
        self.layer_length = 13
        self.a = np.random.random(size=self.layer_length) - 0.5
        self.A = tf.Variable(self.a, trainable=True, dtype=tf.float64)
        self.Carrier = np.random.random() - 0.5
        self.Carrier = tf.Variable(self.Carrier, trainable=True, dtype=tf.float64)
        self.drude = Drude
        self.Ag_nk = Ag_nk
        self.Ge_nk = Ge_nk
        self.ZnS_nk = ZnS_nk
        # self.load_and_interpolate_excel = load_and_interpolate_excel

    def call(self, x):

        frequency_length = tf.size(x)
        print(x,'Wavelength_tensor')
        one_m = tf.constant(1.0, tf.float64)
        zeros_m = tf.constant(0.0, tf.float64)
        x = tf.dtypes.cast(x, tf.float64)
        print('Shape of x is :', tf.shape(x))
        carrier1 = self.Carrier

        # Sigmoid function is used to limit the range of carrier concentration and the layer thickness
##################
        carrier1 = tf.keras.activations.sigmoid(carrier1) * 3.6 + 0.4

    ##########################################

        Ge = tf.complex(4.02 * one_m, zeros_m)
        Ge  = tf.broadcast_to(Ge, [frequency_length, 1])
        SiO = tf.complex(2.20 * one_m, zeros_m)
        #ZnS = tf.broadcast_to(SiO, [frequency_length, 1])
        print('Ge::::：：：：：：：：：：：：：：：：：：：：：：：：：：：：：：：:', Ge)
        Ag = self.Ag_nk(x)
        # Ag = tf.complex(10 * one_m, 20 * one_m)
        # Ag = tf.broadcast_to(Ag, [frequency_length, 1])
        # Ge = self.Ge_nk(x)
        ZnS = self.ZnS_nk(x)
        Ge = self.Ge_nk(x)
        # ZnS_path = "C:/Users/18846/Desktop/nk/ZnS.txt"
        # SiO = generate_complex_values(ZnS_path,x)

        vac = tf.complex(1. * one_m, 0.5*one_m)
        '''vac = tf.broadcast_to(vac, [frequency_length, 1])'''
        CdO1 = self.drude(carrier=carrier1, wavelength=x)
        print(CdO1, 'CdO1_nk')
        sub = vac
        ns = SiO
        n0 = tf.complex(one_m, zeros_m)
        theta_in = one_m * 0 / 180 * 3.1415926
        print(Ge, 'Ge dielectric function')
        d = self.A[-self.layer_length:]
        d = tf.keras.activations.sigmoid(d) * 2 + 0.08
        d = d * 100.
        print(d, 'thickness information')

        print(carrier1, 'carrier concentration')
        vac = tf.broadcast_to(vac, [frequency_length, 1])
        # print('vac:size:::::',tf.size(vac))
        # print(vac)
        # print('vac:type:::::', vac.dtype)
        # Define the substrate, indcident angle
        # Important note: n1 defines the matrial order. For example, here the structure is: Ge-SiO-Ge...-Ge-CdO (with back-calculated carrier concentration)-substrate (highly doped CdO)
        # First layer is vac to make the calculation stable

        #n1 = tf.broadcast_to(n1, [frequency_length, self.layer_length - 1])
        ns = tf.broadcast_to(sub, [frequency_length, 1])
        n0 = tf.broadcast_to(n0, [frequency_length, 1])
        # n1 = [vac, SiO, Ge, SiO, Ge, SiO, Ge]
        # n1 = tf.broadcast_to(n1, [frequency_length, self.layer_length - 2])
        # n1 = tf.reshape(n1,[frequency_length, self.layer_length-2])
        #ns = tf.broadcast_to(sub, [frequency_length, 1])
        d = tf.broadcast_to(d, [frequency_length, self.layer_length])
        x = tf.reshape(x, [frequency_length, ])
        # Concat the dielectric and CdO: (N1 and CdO1 and substrate ns)
        # n = tf.concat([n1, ], axis=1)
        n = tf.concat([ZnS, Ge,  ZnS, Ge, ZnS, ns, Ge, ZnS, Ge, ZnS, Ge, ns, Ag], axis=1)
        # n = tf.concat([vac, Ge, SiO, Ge, SiO, Ge, SiO, Ge, CdO1, ns], axis=1)
        ref = reflectance(x, theta_in, n0, n, d)

        return ref * 100


def Linf(ypred, y):
    res = (ypred - y) ** 2
    res = tf.reduce_max(res)
    return res


# set the target spectra
wavelength, ref_target, wavelength_important, ref_important = set_target()

# AlO = load_and_interpolate_excel(r'C:\Users\18846\Desktop\AlO.xlsx', wavelength)
# print('AlO.................................')
# print(AlO)

# Dataloader, load data into TF data-format
train_ds = tf.data.Dataset.from_tensor_slices((wavelength, ref_target)).shuffle(5000).batch(500)
train_ds2 = tf.data.Dataset.from_tensor_slices((wavelength_important, ref_important)).shuffle(5000).batch(512)

# Define the model
model = MyModel()
tf.keras.backend.set_floatx('float64')
# Define the loss functions. The loss functions are a mixure of meansquareerror + meanabsolute+ Linf
loss_object = tf.keras.losses.MeanSquaredError()
loss_object1 = tf.keras.losses.MeanAbsoluteError()
loss_object3 = Linf

# Important Note: The back propagation is separated into two parts: "important" and "all", the important is the resonance frequency, and all the full frequency range
initial_learning_rate = 0.01
# The learning rate is exponentially decaying, increase the decay steps and epochs for the best performance
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=100,
    decay_rate=0.7,
    staircase=True)

lr_schedule_small_region = tf.keras.optimizers.schedules.ExponentialDecay(
    0.02,
    decay_steps=100,
    decay_rate=0.7,
    staircase=True)

# important Adam optimizer is used.
optimizer1 = tf.keras.optimizers.Adam(learning_rate=lr_schedule_small_region)
optimizer2 = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

train_loss = tf.keras.metrics.Mean(name='train_loss')
test_loss = tf.keras.metrics.Mean(name='test_loss')


@tf.function
def train_step1(images, labels):
    with tf.GradientTape() as tape:
        # training=True is only needed if there are layers with different

        print(model.trainable_variables, 'all variables')
        predictions = model(images, training=True)
        # Important note: here define the loss function component.
        loss = loss_object(labels, predictions) + loss_object1(labels, predictions) * 0.01
        # loss = loss_object(labels, predictions)+loss_object1(labels, predictions)*0.01
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer1.apply_gradients(zip(gradients, model.trainable_variables))

    train_loss(loss)


@tf.function
def train_step2(images, labels):
    with tf.GradientTape() as tape:
        print(model.trainable_variables, 'all variables')
        predictions = model(images, training=True)
        loss = loss_object(labels, predictions) + loss_object1(labels, predictions) * 0.01
        # loss = loss_object(labels, predictions)+loss_object1(labels, predictions)*0.01
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer2.apply_gradients(zip(gradients, model.trainable_variables))

    train_loss(loss)


EPOCHS1 = 200
EPOCHS = 500

# Backpropagation process: firstly backpropagate the resonance part, then the full frequency range
for epoch in range(EPOCHS1):
    # Reset the metrics at the start of the next epoch
    train_loss.reset_states()
    test_loss.reset_states()

    for images, labels in train_ds2:
        train_step1(images, labels)

    if epoch % 1 == 0 or epoch == 0:
        template = 'Epoch {}, Loss: {}'
        print(template.format(epoch + 1,
                              train_loss.result(),

                              ))

for epoch in range(EPOCHS):
    # Reset the metrics at the start of the next epoch
    train_loss.reset_states()
    test_loss.reset_states()

    for images, labels in train_ds:
        train_step2(images, labels)

    if epoch % 1 == 0 or epoch == 0:
        template = 'Epoch {}, Loss: {}'
        print(template.format(epoch + 1,
                              train_loss.result(),

                              ))

# Plot the designed spectra

frequency_len = len(wavelength)
designed_spectra = np.zeros(frequency_len, )
designed_spectra = model(wavelength)

plt.figure()
plt.plot(wavelength, designed_spectra, label='Spectra from inverse design')
plt.plot (wavelength, ref_target, label='target spectra')
# plt.plot(wavelength, designed_spectra, label='Spectra from inverse design')
# plt.plot(wavelength, ref_target, label='target spectra')
plt.title('designed')
plt.xlabel('frequency cm-1')
plt.ylabel('Reflectivity (%)')
plt.legend()

plt.show()

# Important Save the designed spectra
Target_output = np.zeros((frequency_len, 2))
Target_output[:, 0] = wavelength[:, 0]
Target_output[:, 1] = ref_target[:, 0]

Designed_output = np.zeros((frequency_len, 2))
Designed_output[:, 0] = wavelength[:, 0]
Designed_output[:, 1] = designed_spectra

# Print out the parameters of the optical structure, layer thickness and carrier concentration
print(model.trainable_variables)

np.savetxt('target_spectra.csv', Target_output, delimiter=",")
np.savetxt('designed_spectra.csv', Designed_output, delimiter=",")

